{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd9615a-ad11-4db2-9c72-0dbd28380103",
   "metadata": {},
   "source": [
    "## 02 - INITIAL DATA ANALYSIS\n",
    "\n",
    "###### Lecture explaining xarray functionalities geospatial processing : datacubes_data_handling.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af499da-216a-42fd-a7c3-7153f3aed1cd",
   "metadata": {},
   "source": [
    "#### 01.1 - Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a169a1-2183-4339-9903-43057e63959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f572e03e-dd5c-4ccf-8f3c-edd98706f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file NetCDF\n",
    "\n",
    "dataset2 = xr.open_dataset(r\"C:\\Users\\andre\\OneDrive\\Desktop\\Datasets_Geoinfprj\\era5-downscaled-over-italy_hourly_22209.nc\")\n",
    "dataset3 = xr.open_dataset(r\"C:\\Users\\andre\\OneDrive\\Desktop\\Datasets_Geoinfprj\\era5-downscaled-over-italy_hourly_22223.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7531b9a3-896e-4df1-bd89-173abaf64489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_humidity(Ta, Td):\n",
    "    RH = 100 * np.exp((17.625 * Td) / (243.04 + Td) - (17.625 * Ta) / (243.04 + Ta))\n",
    "    return RH\n",
    "\n",
    "def calculate_heat_index(Ta, RH):\n",
    "    HI = (-42.379 + 2.04901523 * Ta + 10.14333127 * RH\n",
    "          - 0.22475541 * Ta * RH - 6.8378e-3 * Ta**2\n",
    "          - 5.48172e-2 * RH**2 + 1.229e-3 * Ta**2 * RH\n",
    "          + 8.528e-4 * Ta * RH**2 - 1.99e-6 * Ta**2 * RH**2)\n",
    "    return HI\n",
    "\n",
    "def calculate_humidex(Ta_K, Td_K):    \n",
    "    # Evita valori troppo bassi per Td (dew point)\n",
    "    Td_K = np.maximum(Td_K, 200)  \n",
    "    \n",
    "    # Calcolo dell'Humidex con formula Masterson\n",
    "    exponent = np.clip(5417.7530 * ((1/273.16) - (1/Td_K)), a_min=None, a_max=500000)\n",
    "    Hu_K = Ta_K + 0.5555 * (6.11 * np.exp(exponent) - 10)\n",
    "    \n",
    "    # Convertiamo alla fine da Kelvin a Celsius\n",
    "    return Hu_K - 273.15\n",
    "\n",
    "# Wet Bulb Globe Temperature\n",
    "def calculate_wbt(Ta, RH):       \n",
    "    WBT = (Ta * np.arctan(0.151977 * np.sqrt(RH + 8.313659)) +\n",
    "           np.arctan(Ta + RH) - np.arctan(RH - 1.676331) +\n",
    "           0.00391838 * RH**1.5 * np.arctan(0.023101 * RH) - 4.686035)\n",
    "    return WBT\n",
    "\n",
    "# Wet Bulb Temperature\n",
    "def calculate_wbgt(Ta, WBT):\n",
    "    WBGT = 0.7 * WBT + 0.3 * Ta\n",
    "    return WBGT\n",
    "\n",
    "def calculate_lethal_heat_stress_index(WBT, RH):\n",
    "    Ls = WBT + 4.5 * (1 - (RH / 100)**2)\n",
    "    return Ls\n",
    "\n",
    "def calculate_utci(Ta, RH):\n",
    "    pa = RH / 100 * 6.105 * np.exp(17.27 * Ta / (237.7 + Ta))\n",
    "    UTCI = Ta + 0.607562 + 0.022771 * Ta - 0.003578 * RH - 0.000119 * Ta * RH\n",
    "    return UTCI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec0c2d2-3e7a-4b7f-8394-a0857e623086",
   "metadata": {},
   "source": [
    "#### Verifica sul singolo timestamp del superamento o meno di tutte le soglie di pericolosità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54681242-8477-43be-8d8f-adfe4e91e321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Confronto Indici vs Soglie per il timestamp selezionato (2023-07-19T14:00:00.000000000) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_214f0_row0_col7, #T_214f0_row0_col8, #T_214f0_row0_col9, #T_214f0_row0_col10, #T_214f0_row0_col11, #T_214f0_row1_col9, #T_214f0_row1_col10, #T_214f0_row1_col11, #T_214f0_row2_col9, #T_214f0_row2_col10, #T_214f0_row2_col11, #T_214f0_row3_col9, #T_214f0_row3_col10, #T_214f0_row3_col11, #T_214f0_row4_col9, #T_214f0_row4_col10, #T_214f0_row4_col11 {\n",
       "  color: red;\n",
       "}\n",
       "#T_214f0_row1_col7, #T_214f0_row1_col8, #T_214f0_row2_col7, #T_214f0_row2_col8, #T_214f0_row3_col7, #T_214f0_row3_col8, #T_214f0_row4_col7, #T_214f0_row4_col8 {\n",
       "  color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_214f0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_214f0_level0_col0\" class=\"col_heading level0 col0\" >Indice</th>\n",
       "      <th id=\"T_214f0_level0_col1\" class=\"col_heading level0 col1\" >Media (°C)</th>\n",
       "      <th id=\"T_214f0_level0_col2\" class=\"col_heading level0 col2\" >Mediana (°C)</th>\n",
       "      <th id=\"T_214f0_level0_col3\" class=\"col_heading level0 col3\" >95° Perc. (°C)</th>\n",
       "      <th id=\"T_214f0_level0_col4\" class=\"col_heading level0 col4\" >99° Perc. (°C)</th>\n",
       "      <th id=\"T_214f0_level0_col5\" class=\"col_heading level0 col5\" >Massimo (°C)</th>\n",
       "      <th id=\"T_214f0_level0_col6\" class=\"col_heading level0 col6\" >Soglia (°C)</th>\n",
       "      <th id=\"T_214f0_level0_col7\" class=\"col_heading level0 col7\" >Media > Soglia</th>\n",
       "      <th id=\"T_214f0_level0_col8\" class=\"col_heading level0 col8\" >Mediana > Soglia</th>\n",
       "      <th id=\"T_214f0_level0_col9\" class=\"col_heading level0 col9\" >95° Perc. > Soglia</th>\n",
       "      <th id=\"T_214f0_level0_col10\" class=\"col_heading level0 col10\" >99° Perc. > Soglia</th>\n",
       "      <th id=\"T_214f0_level0_col11\" class=\"col_heading level0 col11\" >Massimo > Soglia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_214f0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_214f0_row0_col0\" class=\"data row0 col0\" >Heat Index</td>\n",
       "      <td id=\"T_214f0_row0_col1\" class=\"data row0 col1\" >118.314140</td>\n",
       "      <td id=\"T_214f0_row0_col2\" class=\"data row0 col2\" >96.854263</td>\n",
       "      <td id=\"T_214f0_row0_col3\" class=\"data row0 col3\" >240.163476</td>\n",
       "      <td id=\"T_214f0_row0_col4\" class=\"data row0 col4\" >279.980493</td>\n",
       "      <td id=\"T_214f0_row0_col5\" class=\"data row0 col5\" >342.129150</td>\n",
       "      <td id=\"T_214f0_row0_col6\" class=\"data row0 col6\" >40.600000</td>\n",
       "      <td id=\"T_214f0_row0_col7\" class=\"data row0 col7\" >si</td>\n",
       "      <td id=\"T_214f0_row0_col8\" class=\"data row0 col8\" >si</td>\n",
       "      <td id=\"T_214f0_row0_col9\" class=\"data row0 col9\" >si</td>\n",
       "      <td id=\"T_214f0_row0_col10\" class=\"data row0 col10\" >si</td>\n",
       "      <td id=\"T_214f0_row0_col11\" class=\"data row0 col11\" >si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_214f0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_214f0_row1_col0\" class=\"data row1 col0\" >Humidex</td>\n",
       "      <td id=\"T_214f0_row1_col1\" class=\"data row1 col1\" >35.685900</td>\n",
       "      <td id=\"T_214f0_row1_col2\" class=\"data row1 col2\" >39.193636</td>\n",
       "      <td id=\"T_214f0_row1_col3\" class=\"data row1 col3\" >46.237870</td>\n",
       "      <td id=\"T_214f0_row1_col4\" class=\"data row1 col4\" >47.055923</td>\n",
       "      <td id=\"T_214f0_row1_col5\" class=\"data row1 col5\" >47.998297</td>\n",
       "      <td id=\"T_214f0_row1_col6\" class=\"data row1 col6\" >45.000000</td>\n",
       "      <td id=\"T_214f0_row1_col7\" class=\"data row1 col7\" >no</td>\n",
       "      <td id=\"T_214f0_row1_col8\" class=\"data row1 col8\" >no</td>\n",
       "      <td id=\"T_214f0_row1_col9\" class=\"data row1 col9\" >si</td>\n",
       "      <td id=\"T_214f0_row1_col10\" class=\"data row1 col10\" >si</td>\n",
       "      <td id=\"T_214f0_row1_col11\" class=\"data row1 col11\" >si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_214f0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_214f0_row2_col0\" class=\"data row2 col0\" >Lethal Heat Stress Index</td>\n",
       "      <td id=\"T_214f0_row2_col1\" class=\"data row2 col1\" >23.711643</td>\n",
       "      <td id=\"T_214f0_row2_col2\" class=\"data row2 col2\" >25.642181</td>\n",
       "      <td id=\"T_214f0_row2_col3\" class=\"data row2 col3\" >28.233986</td>\n",
       "      <td id=\"T_214f0_row2_col4\" class=\"data row2 col4\" >28.735695</td>\n",
       "      <td id=\"T_214f0_row2_col5\" class=\"data row2 col5\" >29.360319</td>\n",
       "      <td id=\"T_214f0_row2_col6\" class=\"data row2 col6\" >27.000000</td>\n",
       "      <td id=\"T_214f0_row2_col7\" class=\"data row2 col7\" >no</td>\n",
       "      <td id=\"T_214f0_row2_col8\" class=\"data row2 col8\" >no</td>\n",
       "      <td id=\"T_214f0_row2_col9\" class=\"data row2 col9\" >si</td>\n",
       "      <td id=\"T_214f0_row2_col10\" class=\"data row2 col10\" >si</td>\n",
       "      <td id=\"T_214f0_row2_col11\" class=\"data row2 col11\" >si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_214f0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_214f0_row3_col0\" class=\"data row3 col0\" >UTCI</td>\n",
       "      <td id=\"T_214f0_row3_col1\" class=\"data row3 col1\" >34.902576</td>\n",
       "      <td id=\"T_214f0_row3_col2\" class=\"data row3 col2\" >37.245007</td>\n",
       "      <td id=\"T_214f0_row3_col3\" class=\"data row3 col3\" >45.357663</td>\n",
       "      <td id=\"T_214f0_row3_col4\" class=\"data row3 col4\" >46.129793</td>\n",
       "      <td id=\"T_214f0_row3_col5\" class=\"data row3 col5\" >47.215469</td>\n",
       "      <td id=\"T_214f0_row3_col6\" class=\"data row3 col6\" >44.000000</td>\n",
       "      <td id=\"T_214f0_row3_col7\" class=\"data row3 col7\" >no</td>\n",
       "      <td id=\"T_214f0_row3_col8\" class=\"data row3 col8\" >no</td>\n",
       "      <td id=\"T_214f0_row3_col9\" class=\"data row3 col9\" >si</td>\n",
       "      <td id=\"T_214f0_row3_col10\" class=\"data row3 col10\" >si</td>\n",
       "      <td id=\"T_214f0_row3_col11\" class=\"data row3 col11\" >si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_214f0_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_214f0_row4_col0\" class=\"data row4 col0\" >WBGT</td>\n",
       "      <td id=\"T_214f0_row4_col1\" class=\"data row4 col1\" >23.903841</td>\n",
       "      <td id=\"T_214f0_row4_col2\" class=\"data row4 col2\" >26.076931</td>\n",
       "      <td id=\"T_214f0_row4_col3\" class=\"data row4 col3\" >29.661166</td>\n",
       "      <td id=\"T_214f0_row4_col4\" class=\"data row4 col4\" >30.078764</td>\n",
       "      <td id=\"T_214f0_row4_col5\" class=\"data row4 col5\" >30.556419</td>\n",
       "      <td id=\"T_214f0_row4_col6\" class=\"data row4 col6\" >28.000000</td>\n",
       "      <td id=\"T_214f0_row4_col7\" class=\"data row4 col7\" >no</td>\n",
       "      <td id=\"T_214f0_row4_col8\" class=\"data row4 col8\" >no</td>\n",
       "      <td id=\"T_214f0_row4_col9\" class=\"data row4 col9\" >si</td>\n",
       "      <td id=\"T_214f0_row4_col10\" class=\"data row4 col10\" >si</td>\n",
       "      <td id=\"T_214f0_row4_col11\" class=\"data row4 col11\" >si</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x224fb540700>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# **Seleziona un timestamp specifico**\n",
    "time_selected = dataset3['T_2M'].time[23475]\n",
    "\n",
    "# **Estrai temperatura e dew point temperature per il primo timestamp**\n",
    "temperature_snapshot = dataset3['T_2M'].sel(time=time_selected)\n",
    "dew_point_snapshot = dataset2['TD_2M'].sel(time=time_selected)\n",
    "\n",
    "# **Filtra valori anomali e interpoliamo dew point temperature**\n",
    "dew_point_filtered = dew_point_snapshot.where(dew_point_snapshot > 243.15)\n",
    "dew_point_interpolated = dew_point_filtered.interpolate_na(dim='rlat', method='linear').interpolate_na(dim='rlon', method='linear')\n",
    "\n",
    "# **Calcola gli indici per ciascun pixel**\n",
    "humidex_snapshot = calculate_humidex(temperature_snapshot, dew_point_interpolated)\n",
    "relative_humidity_snapshot = calculate_relative_humidity(temperature_snapshot - 273.15, dew_point_interpolated - 273.15)\n",
    "heat_index_snapshot = calculate_heat_index(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "wbt_snapshot = calculate_wbt(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "wbgt_snapshot = calculate_wbgt(temperature_snapshot - 273.15, wbt_snapshot)\n",
    "lhs_snapshot = calculate_lethal_heat_stress_index(wbt_snapshot, relative_humidity_snapshot)\n",
    "utci_snapshot = calculate_utci(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "\n",
    "# **Calcola statistiche per ciascun indice**\n",
    "def calculate_stats(data_array):\n",
    "    return {\n",
    "        \"mean\": data_array.mean().item(),\n",
    "        \"median\": data_array.median().item(),\n",
    "        \"p95\": np.percentile(data_array, 95),\n",
    "        \"p99\": np.percentile(data_array, 99),\n",
    "        \"max\": data_array.max().item()\n",
    "    }\n",
    "\n",
    "indices = {\n",
    "    \"Heat Index\": heat_index_snapshot,\n",
    "    \"Humidex\": humidex_snapshot,\n",
    "    \"Lethal Heat Stress Index\": lhs_snapshot,\n",
    "    \"UTCI\": utci_snapshot,\n",
    "    \"WBGT\": wbgt_snapshot\n",
    "}\n",
    "\n",
    "stats_results = {key: calculate_stats(value) for key, value in indices.items()}\n",
    "\n",
    "# **Definizione delle soglie per ciascun indice**\n",
    "soglie = {\n",
    "    \"Heat Index\": 40.6,\n",
    "    \"Humidex\": 45,\n",
    "    \"Lethal Heat Stress Index\": 27,\n",
    "    \"UTCI\": 44,      # By literature is 46\n",
    "    \"WBGT\": 28       # By literature is 30\n",
    "}\n",
    "\n",
    "# **Creazione del DataFrame con i risultati**\n",
    "df_results = pd.DataFrame([\n",
    "    {\n",
    "        \"Indice\": key,\n",
    "        \"Media (°C)\": value[\"mean\"],\n",
    "        \"Mediana (°C)\": value[\"median\"],\n",
    "        \"95° Perc. (°C)\": value[\"p95\"],\n",
    "        \"99° Perc. (°C)\": value[\"p99\"],\n",
    "        \"Massimo (°C)\": value[\"max\"],\n",
    "        \"Soglia (°C)\": soglie[key],\n",
    "        \"Media > Soglia\": \"si\" if value[\"mean\"] > soglie[key] else \"no\",\n",
    "        \"Mediana > Soglia\": \"si\" if value[\"median\"] > soglie[key] else \"no\",\n",
    "        \"95° Perc. > Soglia\": \"si\" if value[\"p95\"] > soglie[key] else \"no\",\n",
    "        \"99° Perc. > Soglia\": \"si\" if value[\"p99\"] > soglie[key] else \"no\",\n",
    "        \"Massimo > Soglia\": \"si\" if value[\"max\"] > soglie[key] else \"no\"\n",
    "    }\n",
    "    for key, value in stats_results.items()\n",
    "])\n",
    "\n",
    "# **Ordina il DataFrame**\n",
    "df_results.sort_values(by=\"Indice\", inplace=True)\n",
    "\n",
    "# **Funzione per colorare i \"si\" di rosso e i \"no\" di verde**\n",
    "def color_superamento(val):\n",
    "    color = \"red\" if val == \"si\" else \"green\"\n",
    "    return f\"color: {color}\"\n",
    "\n",
    "# **Applica la formattazione condizionale**\n",
    "df_styled = df_results.style.applymap(color_superamento, subset=[\"Media > Soglia\", \"Mediana > Soglia\", \"95° Perc. > Soglia\", \"99° Perc. > Soglia\", \"Massimo > Soglia\"])\n",
    "\n",
    "# **Visualizza il DataFrame formattato con il timestamp in analisi**\n",
    "print(f\"\\n=== Confronto Indici vs Soglie per il timestamp selezionato ({str(time_selected.values)}) ===\")\n",
    "df_styled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39277130-47d8-4ad4-bc5c-f16f495e958f",
   "metadata": {},
   "source": [
    "#### Criterias to identify heat waves\n",
    "\n",
    "| Index | Threshold value by literature | Threshold value used |\n",
    "|:--|:--|:--|\n",
    "| Heat Index (HI) | > 105°F (~40.6°C) |\n",
    "| Humidex (Hu) | > 45°C |\n",
    "| WBGT | > 30°C | > 28°C |\n",
    "| Lethal Heat Stress Index (Ls) | > 27°C |\n",
    "| UTCI | > 46°C | > 44°C |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b33c0bf-8c47-4ed9-a93b-c4cbdc07e6a7",
   "metadata": {},
   "source": [
    "#### Verifica su tutti i timestamp di un anno del superamento o meno di tutte le soglie di pericolosità & selezione dei giorni consecutivi in cui ciò accade -> heat wave vs casi isolati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78333e34-678a-4686-93f9-426a2c20734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# **Seleziona un anno specifico per l'analisi**\n",
    "year = 2022\n",
    "timestamps = dataset3['T_2M'].time.sel(time=dataset3['T_2M'].time.dt.year == year)\n",
    "\n",
    "# **Definizione delle soglie per ciascun indice**\n",
    "soglie = {\n",
    "    \"Heat Index\": 40.6,\n",
    "    \"Humidex\": 45,\n",
    "    \"Lethal Heat Stress Index\": 27,\n",
    "    \"UTCI\": 46,\n",
    "    \"WBGT\": 30\n",
    "}\n",
    "\n",
    "# **Lista per salvare i risultati finali**\n",
    "heatwave_records = []\n",
    "\n",
    "# **Itera su tutti i timestamp dell'anno selezionato**\n",
    "for i, time_selected in enumerate(timestamps):\n",
    "    \n",
    "    # **Estrai temperatura e dew point per il timestamp attuale**\n",
    "    temperature_snapshot = dataset3['T_2M'].sel(time=time_selected)\n",
    "    dew_point_snapshot = dataset2['TD_2M'].sel(time=time_selected)\n",
    "    \n",
    "    # **Filtra valori anomali e interpoliamo dew point temperature**\n",
    "    dew_point_filtered = dew_point_snapshot.where(dew_point_snapshot > 243.15)\n",
    "    dew_point_interpolated = dew_point_filtered.interpolate_na(dim='rlat', method='linear').interpolate_na(dim='rlon', method='linear')\n",
    "\n",
    "    # **Calcola gli indici per ciascun pixel**\n",
    "    humidex_snapshot = calculate_humidex(temperature_snapshot, dew_point_interpolated)\n",
    "    relative_humidity_snapshot = calculate_relative_humidity(temperature_snapshot - 273.15, dew_point_interpolated - 273.15)\n",
    "    heat_index_snapshot = calculate_heat_index(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "    wbt_snapshot = calculate_wbt(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "    wbgt_snapshot = calculate_wbgt(temperature_snapshot - 273.15, wbt_snapshot)\n",
    "    lhs_snapshot = calculate_lethal_heat_stress_index(wbt_snapshot, relative_humidity_snapshot)\n",
    "    utci_snapshot = calculate_utci(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "\n",
    "    # **Calcola statistiche per ciascun indice**\n",
    "    def calculate_stats(data_array):\n",
    "        return {\n",
    "            \"mean\": data_array.mean().item(),\n",
    "            \"median\": data_array.median().item(),\n",
    "            \"p95\": np.percentile(data_array, 95),\n",
    "            \"p99\": np.percentile(data_array, 99),\n",
    "            \"max\": data_array.max().item()\n",
    "        }\n",
    "\n",
    "    indices = {\n",
    "        \"Heat Index\": heat_index_snapshot,\n",
    "        \"Humidex\": humidex_snapshot,\n",
    "        \"Lethal Heat Stress Index\": lhs_snapshot,\n",
    "        \"UTCI\": utci_snapshot,\n",
    "        \"WBGT\": wbgt_snapshot\n",
    "    }\n",
    "\n",
    "    stats_results = {key: calculate_stats(value) for key, value in indices.items()}\n",
    "\n",
    "    # **Verifica se TUTTI gli indici superano almeno in una delle colonne le soglie**\n",
    "    all_exceed = all(\n",
    "        any([\n",
    "            stats_results[key][\"mean\"] > soglie[key],\n",
    "            stats_results[key][\"median\"] > soglie[key],\n",
    "            stats_results[key][\"p95\"] > soglie[key],\n",
    "            stats_results[key][\"p99\"] > soglie[key],\n",
    "            stats_results[key][\"max\"] > soglie[key]\n",
    "        ])\n",
    "        for key in indices.keys()\n",
    "    )\n",
    "\n",
    "    # **Se la condizione è soddisfatta, salva il risultato**\n",
    "    if all_exceed:\n",
    "        \n",
    "        df_results = pd.DataFrame([\n",
    "            {\n",
    "                \"Indice\": key,\n",
    "                \"Media (°C)\": value[\"mean\"],\n",
    "                \"Mediana (°C)\": value[\"median\"],\n",
    "                \"95° Perc. (°C)\": value[\"p95\"],\n",
    "                \"99° Perc. (°C)\": value[\"p99\"],\n",
    "                \"Massimo (°C)\": value[\"max\"],\n",
    "                \"Soglia (°C)\": soglie[key],\n",
    "                \"Media > Soglia\": \"si\" if value[\"mean\"] > soglie[key] else \"no\",\n",
    "                \"Mediana > Soglia\": \"si\" if value[\"median\"] > soglie[key] else \"no\",\n",
    "                \"95° Perc. > Soglia\": \"si\" if value[\"p95\"] > soglie[key] else \"no\",\n",
    "                \"99° Perc. > Soglia\": \"si\" if value[\"p99\"] > soglie[key] else \"no\",\n",
    "                \"Massimo > Soglia\": \"si\" if value[\"max\"] > soglie[key] else \"no\"\n",
    "            }\n",
    "            for key, value in stats_results.items()\n",
    "        ])\n",
    "        \n",
    "        # **Aggiunta di timestamp nel dataframe per chiarezza**\n",
    "        df_results.insert(0, \"Timestamp\", str(time_selected.values))\n",
    "        df_results.insert(1, \"Numero Timestamp\", i)\n",
    "\n",
    "        # **Aggiungi i risultati alla lista per il salvataggio**\n",
    "        heatwave_records.extend(df_results.to_dict(orient=\"records\"))\n",
    "\n",
    "# **Creazione del DataFrame finale**\n",
    "df_heatwave = pd.DataFrame(heatwave_records)\n",
    "\n",
    "# **Identificazione di heat wave e casi isolati**\n",
    "df_heatwave[\"Data\"] = pd.to_datetime(df_heatwave[\"Timestamp\"]).dt.date\n",
    "df_heatwave[\"Heat Wave\"] = \"caso isolato\"\n",
    "\n",
    "for i, row in df_heatwave.iterrows():\n",
    "    current_date = row[\"Data\"]\n",
    "    next_day = current_date + pd.Timedelta(days=1)\n",
    "    prev_day = current_date - pd.Timedelta(days=1)\n",
    "\n",
    "    if ((next_day in df_heatwave[\"Data\"].values) or (prev_day in df_heatwave[\"Data\"].values)):\n",
    "        df_heatwave.at[i, \"Heat Wave\"] = \"heat wave\"\n",
    "\n",
    "# **Salvataggio su file CSV con nome contenente l'anno**\n",
    "df_heatwave.to_csv(f\"heatwave_timestamps_{year}.csv\", index=False)\n",
    "\n",
    "# **Controllo per stampare il messaggio appropriato**\n",
    "print(\"\\n=== Giorni con Ondate di Calore Estreme dell'anno selezionato ===\")\n",
    "if df_heatwave.empty:\n",
    "    print(\"Nessun giorno dell'anno selezionato ha superato tutte le soglie di pericolosità per il caldo estremo nel 95° percentile.\")\n",
    "else:\n",
    "    print(\"Stampa nella cella successiva df_heatwave per vederlo in formato data frame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade8a5d-f8b1-4da2-9613-e48bb05392a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heatwave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b303b0-489c-430f-8a28-d2564228225c",
   "metadata": {},
   "source": [
    "#### GIF rappresentante il periodo prima durante e dopo la heat wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b1e93a16-1896-4722-a667-993f465d949e",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " GIF creata con successo: heatwave_evolution_2022.gif\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v2 as imageio  # Evita il warning di ImageIO\n",
    "import os\n",
    "\n",
    "# **Parametri personalizzabili**\n",
    "year = 2022  # Anno di analisi\n",
    "target_timestamp_index = 309  # Numero del timestamp di riferimento (cambiabile dall'utente)\n",
    "days_before = 10  # Giorni precedenti da mostrare\n",
    "days_after = 12  # Giorni successivi da mostrare\n",
    "indice_selezionato = \"Heat Index\"  # Indice da visualizzare nella mappa\n",
    "\n",
    "# **Caricamento dei dati**\n",
    "timestamps = dataset3['T_2M'].time.sel(time=dataset3['T_2M'].time.dt.year == year)\n",
    "df_heatwave[\"Data\"] = pd.to_datetime(df_heatwave[\"Timestamp\"]).dt.date\n",
    "heatwave_days = df_heatwave[df_heatwave['Heat Wave'] == 'heat wave']['Data'].unique()\n",
    "heatwave_dates = set(str(date) for date in heatwave_days)  # Set di date formattate\n",
    "\n",
    "# **Seleziona il timestamp di riferimento**\n",
    "target_time = timestamps[target_timestamp_index]\n",
    "\n",
    "# **Definiamo l'intervallo temporale per la GIF**\n",
    "start_time = target_time - np.timedelta64(days_before, 'D')\n",
    "end_time = target_time + np.timedelta64(days_after, 'D')\n",
    "time_range = timestamps.sel(time=(timestamps >= start_time) & (timestamps <= end_time))\n",
    "\n",
    "# **Calcola il range fisso per la legenda solo sui timestamp selezionati**\n",
    "heat_index_values = []\n",
    "for time_selected in time_range:\n",
    "    temperature_snapshot = dataset3['T_2M'].sel(time=time_selected)\n",
    "    dew_point_snapshot = dataset2['TD_2M'].sel(time=time_selected)\n",
    "    dew_point_filtered = dew_point_snapshot.where(dew_point_snapshot > 243.15)\n",
    "    dew_point_interpolated = dew_point_filtered.interpolate_na(dim='rlat', method='linear').interpolate_na(dim='rlon', method='linear')\n",
    "    heat_index_snapshot = calculate_heat_index(temperature_snapshot - 273.15, calculate_relative_humidity(temperature_snapshot - 273.15, dew_point_interpolated - 273.15))\n",
    "    heat_index_values.append(heat_index_snapshot.values)\n",
    "\n",
    "heat_index_values = np.concatenate([hi.flatten() for hi in heat_index_values])\n",
    "heat_index_min = heat_index_values.min()\n",
    "heat_index_max = heat_index_values.max()\n",
    "\n",
    "# **Creazione di una cartella temporanea per le immagini**\n",
    "output_folder = \"temp_frames\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# **Genera i frame per la GIF**\n",
    "frames = []\n",
    "for time_selected in time_range:\n",
    "    \n",
    "    # **Estrai i dati di temperatura e dew point**\n",
    "    temperature_snapshot = dataset3['T_2M'].sel(time=time_selected)\n",
    "    dew_point_snapshot = dataset2['TD_2M'].sel(time=time_selected)\n",
    "    \n",
    "    # **Filtra valori anomali e interpoliamo dew point temperature**\n",
    "    dew_point_filtered = dew_point_snapshot.where(dew_point_snapshot > 243.15)\n",
    "    dew_point_interpolated = dew_point_filtered.interpolate_na(dim='rlat', method='linear').interpolate_na(dim='rlon', method='linear')\n",
    "    \n",
    "    # **Calcola gli indici**\n",
    "    heat_index_snapshot = calculate_heat_index(temperature_snapshot - 273.15, calculate_relative_humidity(temperature_snapshot - 273.15, dew_point_interpolated - 273.15))\n",
    "    \n",
    "    # **Plotta la distribuzione dell'Heat Index per il timestamp corrente**\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    im = ax.imshow(heat_index_snapshot, cmap=\"inferno\", origin=\"lower\", vmin=heat_index_min, vmax=heat_index_max)\n",
    "    \n",
    "    # **Legenda fissa**\n",
    "    cbar = plt.colorbar(im, label=\"Heat Index (°C)\")\n",
    "    cbar.ax.tick_params(labelsize=10)\n",
    "    \n",
    "    # **Aggiungi il titolo con il timestamp e indicazione della heatwave**\n",
    "    timestamp_str = str(time_selected.values)[:16]\n",
    "    ax.set_title(timestamp_str, fontsize=14, fontweight=\"bold\", ha='left', x=0)\n",
    "    \n",
    "    # **Se il giorno è una heatwave, evidenzia il riquadro e mostra la scritta**\n",
    "    date_str = timestamp_str[:10]  # Estrai solo la parte di data\n",
    "    if date_str in heatwave_dates:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('red')\n",
    "            spine.set_linewidth(3)\n",
    "        ax.text(0.5, -0.1, \"HEAT WAVE HIT\", fontsize=18, color='red', ha='center', transform=ax.transAxes, fontweight='bold')\n",
    "    \n",
    "    # **Sostituisci i caratteri speciali per evitare errori nei nomi dei file**\n",
    "    safe_timestamp = timestamp_str.replace(\":\", \"-\").replace(\"T\", \"_\").split(\".\")[0]\n",
    "    frame_filename = os.path.join(output_folder, f\"frame_{safe_timestamp}.png\")\n",
    "\n",
    "    # **Salva il frame temporaneo**\n",
    "    plt.savefig(frame_filename, dpi=100)\n",
    "    plt.close()\n",
    "    \n",
    "    frames.append(frame_filename)\n",
    "\n",
    "# **Creazione della GIF**\n",
    "gif_filename = f\"heatwave_evolution_{year}.gif\"\n",
    "with imageio.get_writer(gif_filename, mode='I', duration=5) as writer:\n",
    "    for frame in frames:\n",
    "        image = imageio.imread(frame)\n",
    "        writer.append_data(image)\n",
    "\n",
    "# **Pulizia della cartella temporanea**\n",
    "for frame in frames:\n",
    "    try:\n",
    "        os.remove(frame)\n",
    "    except PermissionError:\n",
    "        pass  # Ignora errori se il file è ancora in uso\n",
    "try:\n",
    "    os.rmdir(output_folder)\n",
    "except PermissionError:\n",
    "    pass  # Ignora errori se la cartella è ancora in uso\n",
    "\n",
    "print(f\"\\n GIF creata con successo: {gif_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617eb930-c42a-427e-b1b3-c267c11ee7bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Iterazione dall'inizio del dataset del superamento o meno di tutte le soglie di pericolosità per tutti gli anni, che si arresta quando trovato un anno con almeno un timestamp che supera tutte le soglie di pericolosità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c81b1ce-1730-409d-a8f6-de27305920f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Analizzando l'anno 1981...\n",
      "\n",
      "🔍 Analizzando l'anno 1982...\n",
      "\n",
      "🔍 Analizzando l'anno 1983...\n",
      "\n",
      "🔍 Analizzando l'anno 1984...\n",
      "\n",
      "🔍 Analizzando l'anno 1985...\n",
      "\n",
      "🔍 Analizzando l'anno 1986...\n",
      "\n",
      "🔍 Analizzando l'anno 1987...\n",
      "\n",
      "🔍 Analizzando l'anno 1988...\n",
      "\n",
      "🔍 Analizzando l'anno 1989...\n",
      "\n",
      "🔍 Analizzando l'anno 1990...\n",
      "\n",
      "🔍 Analizzando l'anno 1991...\n",
      "\n",
      "🔍 Analizzando l'anno 1992...\n",
      "\n",
      "🔍 Analizzando l'anno 1993...\n",
      "\n",
      "🔍 Analizzando l'anno 1994...\n",
      "\n",
      "🔍 Analizzando l'anno 1995...\n",
      "\n",
      "🔍 Analizzando l'anno 1996...\n",
      "\n",
      "🔍 Analizzando l'anno 1997...\n",
      "\n",
      "🔍 Analizzando l'anno 1998...\n",
      "\n",
      "🔍 Analizzando l'anno 1999...\n",
      "\n",
      "🔍 Analizzando l'anno 2000...\n",
      "\n",
      "🔍 Analizzando l'anno 2001...\n",
      "\n",
      "🔍 Analizzando l'anno 2002...\n",
      "\n",
      "🔍 Analizzando l'anno 2003...\n",
      "\n",
      "🔍 Analizzando l'anno 2004...\n",
      "\n",
      "🔍 Analizzando l'anno 2005...\n",
      "\n",
      "🔍 Analizzando l'anno 2006...\n",
      "\n",
      "🔍 Analizzando l'anno 2007...\n",
      "\n",
      "🔍 Analizzando l'anno 2008...\n",
      "\n",
      "🔍 Analizzando l'anno 2009...\n",
      "\n",
      "🔍 Analizzando l'anno 2010...\n",
      "\n",
      "🔍 Analizzando l'anno 2011...\n",
      "\n",
      "🔍 Analizzando l'anno 2012...\n",
      "\n",
      "🔍 Analizzando l'anno 2013...\n",
      "\n",
      "🔍 Analizzando l'anno 2014...\n",
      "\n",
      "🔍 Analizzando l'anno 2015...\n",
      "\n",
      "🔍 Analizzando l'anno 2016...\n",
      "\n",
      "🔍 Analizzando l'anno 2017...\n",
      "\n",
      "🔍 Analizzando l'anno 2018...\n",
      "\n",
      "🔍 Analizzando l'anno 2019...\n",
      "\n",
      "🔍 Analizzando l'anno 2020...\n",
      "\n",
      "🔍 Analizzando l'anno 2021...\n",
      "\n",
      "🔍 Analizzando l'anno 2022...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m humidex_snapshot \u001b[38;5;241m=\u001b[39m calculate_humidex(temperature_snapshot, dew_point_interpolated)\n\u001b[0;32m     42\u001b[0m relative_humidity_snapshot \u001b[38;5;241m=\u001b[39m calculate_relative_humidity(temperature_snapshot \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m273.15\u001b[39m, dew_point_interpolated \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m273.15\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m heat_index_snapshot \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_heat_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemperature_snapshot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m273.15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelative_humidity_snapshot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m wbt_snapshot \u001b[38;5;241m=\u001b[39m calculate_wbt(temperature_snapshot \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m273.15\u001b[39m, relative_humidity_snapshot)\n\u001b[0;32m     45\u001b[0m wbgt_snapshot \u001b[38;5;241m=\u001b[39m calculate_wbgt(temperature_snapshot \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m273.15\u001b[39m, wbt_snapshot)\n",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m, in \u001b[0;36mcalculate_heat_index\u001b[1;34m(Ta, RH)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcalculate_heat_index\u001b[39m(Ta, RH):\n\u001b[1;32m----> 6\u001b[0m     HI \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m42.379\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.04901523\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10.14333127\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRH\u001b[49m\n\u001b[0;32m      7\u001b[0m           \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.22475541\u001b[39m \u001b[38;5;241m*\u001b[39m Ta \u001b[38;5;241m*\u001b[39m RH \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m6.8378e-3\u001b[39m \u001b[38;5;241m*\u001b[39m Ta\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      8\u001b[0m           \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m5.48172e-2\u001b[39m \u001b[38;5;241m*\u001b[39m RH\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.229e-3\u001b[39m \u001b[38;5;241m*\u001b[39m Ta\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m RH\n\u001b[0;32m      9\u001b[0m           \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m8.528e-4\u001b[39m \u001b[38;5;241m*\u001b[39m Ta \u001b[38;5;241m*\u001b[39m RH\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.99e-6\u001b[39m \u001b[38;5;241m*\u001b[39m Ta\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m RH\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m HI\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\_typed_ops.py:206\u001b[0m, in \u001b[0;36mDataArrayOpsMixin.__add__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_binary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\dataarray.py:4371\u001b[0m, in \u001b[0;36mDataArray._binary_op\u001b[1;34m(self, other, f, reflexive)\u001b[0m\n\u001b[0;32m   4364\u001b[0m other_coords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(other, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoords\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   4366\u001b[0m variable \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4367\u001b[0m     f(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariable, other_variable)\n\u001b[0;32m   4368\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reflexive\n\u001b[0;32m   4369\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m f(other_variable, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariable)\n\u001b[0;32m   4370\u001b[0m )\n\u001b[1;32m-> 4371\u001b[0m coords, indexes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreflexive\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4372\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_name(other)\n\u001b[0;32m   4374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replace(variable, coords, name, indexes\u001b[38;5;241m=\u001b[39mindexes)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\coordinates.py:186\u001b[0m, in \u001b[0;36mCoordinates._merge_raw\u001b[1;34m(self, other, reflexive)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     coord_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m, other] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reflexive \u001b[38;5;28;01melse\u001b[39;00m [other, \u001b[38;5;28mself\u001b[39m]\n\u001b[1;32m--> 186\u001b[0m     variables, indexes \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_coordinates_without_align\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoord_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m variables, indexes\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\merge.py:420\u001b[0m, in \u001b[0;36mmerge_coordinates_without_align\u001b[1;34m(objects, prioritized, exclude_dims, combine_attrs)\u001b[0m\n\u001b[0;32m    416\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m collected\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# TODO: indexes should probably be filtered in collected elements\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# before merging them\u001b[39;00m\n\u001b[1;32m--> 420\u001b[0m merged_coords, merged_indexes \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprioritized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    423\u001b[0m merged_indexes \u001b[38;5;241m=\u001b[39m filter_indexes_from_coords(merged_indexes, \u001b[38;5;28mset\u001b[39m(merged_coords))\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merged_coords, merged_indexes\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\merge.py:302\u001b[0m, in \u001b[0;36mmerge_collected\u001b[1;34m(grouped, prioritized, compat, combine_attrs, equals)\u001b[0m\n\u001b[0;32m    300\u001b[0m variables \u001b[38;5;241m=\u001b[39m [variable \u001b[38;5;28;01mfor\u001b[39;00m variable, _ \u001b[38;5;129;01min\u001b[39;00m elements_list]\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 302\u001b[0m     merged_vars[name] \u001b[38;5;241m=\u001b[39m \u001b[43munique_variable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mequals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MergeError:\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compat \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;66;03m# we need more than \"minimal\" compatibility (for which\u001b[39;00m\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;66;03m# we drop conflicting coordinates)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\merge.py:149\u001b[0m, in \u001b[0;36munique_variable\u001b[1;34m(name, variables, compat, equals)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m equals \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;66;03m# now compare values with minimum number of computes\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m variables[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m    151\u001b[0m         equals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(out, compat)(var)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\variable.py:563\u001b[0m, in \u001b[0;36mVariable.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this variable's data from disk or a\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03mremote source into memory and return a new variable. The original is\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;124;03mleft unaltered.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;124;03mdask.array.compute\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    562\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\variable.py:538\u001b[0m, in \u001b[0;36mVariable.load\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    522\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this variable's data from disk or a\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;124;03m    remote source into memory and return this variable.\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03m    dask.array.compute\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_duck_dask_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    539\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m as_compatible_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcompute(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_duck_array(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\pycompat.py:81\u001b[0m, in \u001b[0;36mis_duck_dask_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mis_duck_dask_array\u001b[39m(x):\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m is_duck_array(x) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mis_dask_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\pycompat.py:73\u001b[0m, in \u001b[0;36mis_dask_collection\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mis_dask_collection\u001b[39m(x):\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmodule_available\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_dask_collection\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m is_dask_collection(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\utils.py:1161\u001b[0m, in \u001b[0;36mmodule_available\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmodule_available\u001b[39m(module: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Checks whether a module is installed without importing it.\u001b[39;00m\n\u001b[0;32m   1148\u001b[0m \n\u001b[0;32m   1149\u001b[0m \u001b[38;5;124;03m    Use this for a lightweight check and lazy imports.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;124;03m        Whether the module is installed.\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\importlib\\util.py:103\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    102\u001b[0m         parent_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_find_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[fullname]\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:914\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1407\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1379\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1506\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:142\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# **Definizione delle soglie per ciascun indice**\n",
    "soglie = {\n",
    "    \"Heat Index\": 40.6,\n",
    "    \"Humidex\": 45,\n",
    "    \"Lethal Heat Stress Index\": 27,\n",
    "    \"UTCI\": 46,\n",
    "    \"WBGT\": 30\n",
    "}\n",
    "\n",
    "# **Ottieni tutti gli anni disponibili nel dataset**\n",
    "anni_disponibili = np.unique(dataset3['T_2M'].time.dt.year.values)\n",
    "\n",
    "# **Variabile per verificare se abbiamo trovato un anno con heatwave**\n",
    "anno_trovato = False\n",
    "\n",
    "# **Iteriamo su tutti gli anni disponibili**\n",
    "for year in anni_disponibili:\n",
    "    if anno_trovato:\n",
    "        break  # Se abbiamo già trovato un anno valido, interrompiamo il loop\n",
    "\n",
    "    print(f\"\\n🔍 Analizzando l'anno {year}...\")\n",
    "\n",
    "    # **Seleziona i timestamp per l'anno corrente**\n",
    "    timestamps = dataset3['T_2M'].time.sel(time=dataset3['T_2M'].time.dt.year == year)\n",
    "\n",
    "    # **Lista per salvare i giorni in cui tutte le soglie vengono superate**\n",
    "    heatwave_days = []\n",
    "\n",
    "    # **Itera su tutti i timestamp dell'anno selezionato**\n",
    "    for time_selected in timestamps:\n",
    "        \n",
    "        # **Estrai temperatura e dew point per il timestamp attuale**\n",
    "        temperature_snapshot = dataset3['T_2M'].sel(time=time_selected)\n",
    "        dew_point_snapshot = dataset2['TD_2M'].sel(time=time_selected)\n",
    "        \n",
    "        # **Filtra valori anomali e interpoliamo dew point temperature**\n",
    "        dew_point_filtered = dew_point_snapshot.where(dew_point_snapshot > 243.15)\n",
    "        dew_point_interpolated = dew_point_filtered.interpolate_na(dim='rlat', method='linear').interpolate_na(dim='rlon', method='linear')\n",
    "\n",
    "        # **Calcola gli indici per ciascun pixel**\n",
    "        humidex_snapshot = calculate_humidex(temperature_snapshot, dew_point_interpolated)\n",
    "        relative_humidity_snapshot = calculate_relative_humidity(temperature_snapshot - 273.15, dew_point_interpolated - 273.15)\n",
    "        heat_index_snapshot = calculate_heat_index(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "        wbt_snapshot = calculate_wbt(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "        wbgt_snapshot = calculate_wbgt(temperature_snapshot - 273.15, wbt_snapshot)\n",
    "        lhs_snapshot = calculate_lethal_heat_stress_index(wbt_snapshot, relative_humidity_snapshot)\n",
    "        utci_snapshot = calculate_utci(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "\n",
    "        # **Calcola media e mediana per ciascun indice**\n",
    "        humidex_mean, humidex_median = humidex_snapshot.mean().item(), humidex_snapshot.median().item()\n",
    "        heat_index_mean, heat_index_median = heat_index_snapshot.mean().item(), heat_index_snapshot.median().item()\n",
    "        wbgt_mean, wbgt_median = wbgt_snapshot.mean().item(), wbgt_snapshot.median().item()\n",
    "        lhs_mean, lhs_median = lhs_snapshot.mean().item(), lhs_snapshot.median().item()\n",
    "        utci_mean, utci_median = utci_snapshot.mean().item(), utci_snapshot.median().item()\n",
    "\n",
    "        # **Verifica se tutti gli indici superano le soglie contemporaneamente**\n",
    "        all_indices_above_threshold = (\n",
    "            (heat_index_mean > soglie[\"Heat Index\"]) and (heat_index_median > soglie[\"Heat Index\"]) and\n",
    "            (humidex_mean > soglie[\"Humidex\"]) and (humidex_median > soglie[\"Humidex\"]) and\n",
    "            (lhs_mean > soglie[\"Lethal Heat Stress Index\"]) and (lhs_median > soglie[\"Lethal Heat Stress Index\"]) and\n",
    "            (utci_mean > soglie[\"UTCI\"]) and (utci_median > soglie[\"UTCI\"]) and\n",
    "            (wbgt_mean > soglie[\"WBGT\"]) and (wbgt_median > soglie[\"WBGT\"])\n",
    "        )\n",
    "\n",
    "        # **Se la condizione è soddisfatta, aggiungiamo il giorno alla lista**\n",
    "        if all_indices_above_threshold:\n",
    "            heatwave_days.append(str(time_selected.values))\n",
    "            anno_trovato = True  # Imposta il flag per fermare la ricerca dopo questo anno\n",
    "\n",
    "    # **Se abbiamo trovato almeno un giorno, interrompiamo il loop**\n",
    "    if anno_trovato:\n",
    "        break\n",
    "\n",
    "# **Se abbiamo trovato un anno valido, creiamo il DataFrame**\n",
    "if anno_trovato and heatwave_days:\n",
    "    df_heatwave_days = pd.DataFrame({\"Heatwave Days\": heatwave_days})\n",
    "\n",
    "    # **Ordina i risultati in base alla data**\n",
    "    df_heatwave_days.sort_values(by=\"Heatwave Days\", inplace=True)\n",
    "\n",
    "    # **Esporta il DataFrame in un file CSV per visualizzazione**\n",
    "    df_heatwave_days.to_csv(f\"heatwave_days_{year}.csv\", index=False)\n",
    "\n",
    "    # **Stampa i risultati**\n",
    "    print(f\"\\n=== Giorni con Ondate di Calore Estreme nell'anno {year} ===\")\n",
    "    print(df_heatwave_days.to_string(index=False))\n",
    "\n",
    "else:\n",
    "    print(\"\\n Nessun anno nel dataset ha superato tutte le soglie di pericolosità per il caldo estremo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af1a2b-c97c-4843-ae17-e66be072be53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
