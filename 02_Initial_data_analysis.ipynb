{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd9615a-ad11-4db2-9c72-0dbd28380103",
   "metadata": {},
   "source": [
    "## 02 - INITIAL DATA ANALYSIS\n",
    "\n",
    "###### Lecture explaining xarray functionalities geospatial processing : datacubes_data_handling.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af499da-216a-42fd-a7c3-7153f3aed1cd",
   "metadata": {},
   "source": [
    "#### 01.1 - Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a169a1-2183-4339-9903-43057e63959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f572e03e-dd5c-4ccf-8f3c-edd98706f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file NetCDF\n",
    "\n",
    "dataset2 = xr.open_dataset(r\"C:\\Users\\andre\\OneDrive\\Desktop\\Datasets_Geoinfprj\\era5-downscaled-over-italy_hourly_22209.nc\")\n",
    "dataset3 = xr.open_dataset(r\"C:\\Users\\andre\\OneDrive\\Desktop\\Datasets_Geoinfprj\\era5-downscaled-over-italy_hourly_22223.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7531b9a3-896e-4df1-bd89-173abaf64489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_humidity(Ta, Td):\n",
    "    RH = 100 * np.exp((17.625 * Td) / (243.04 + Td) - (17.625 * Ta) / (243.04 + Ta))\n",
    "    return RH\n",
    "\n",
    "def calculate_heat_index(Ta, RH):\n",
    "    HI = (-42.379 + 2.04901523 * Ta + 10.14333127 * RH\n",
    "          - 0.22475541 * Ta * RH - 6.8378e-3 * Ta**2\n",
    "          - 5.48172e-2 * RH**2 + 1.229e-3 * Ta**2 * RH\n",
    "          + 8.528e-4 * Ta * RH**2 - 1.99e-6 * Ta**2 * RH**2)\n",
    "    return HI\n",
    "\n",
    "def calculate_humidex(Ta_K, Td_K):    \n",
    "    # Evita valori troppo bassi per Td (dew point)\n",
    "    Td_K = np.maximum(Td_K, 200)  \n",
    "    \n",
    "    # Calcolo dell'Humidex con formula Masterson\n",
    "    exponent = np.clip(5417.7530 * ((1/273.16) - (1/Td_K)), a_min=None, a_max=500000)\n",
    "    Hu_K = Ta_K + 0.5555 * (6.11 * np.exp(exponent) - 10)\n",
    "    \n",
    "    # Convertiamo alla fine da Kelvin a Celsius\n",
    "    return Hu_K - 273.15\n",
    "\n",
    "# Wet Bulb Globe Temperature\n",
    "def calculate_wbt(Ta, RH):       \n",
    "    WBT = (Ta * np.arctan(0.151977 * np.sqrt(RH + 8.313659)) +\n",
    "           np.arctan(Ta + RH) - np.arctan(RH - 1.676331) +\n",
    "           0.00391838 * RH**1.5 * np.arctan(0.023101 * RH) - 4.686035)\n",
    "    return WBT\n",
    "\n",
    "# Wet Bulb Temperature\n",
    "def calculate_wbgt(Ta, WBT):\n",
    "    WBGT = 0.7 * WBT + 0.3 * Ta\n",
    "    return WBGT\n",
    "\n",
    "def calculate_lethal_heat_stress_index(WBT, RH):\n",
    "    Ls = WBT + 4.5 * (1 - (RH / 100)**2)\n",
    "    return Ls\n",
    "\n",
    "def calculate_utci(Ta, RH):\n",
    "    pa = RH / 100 * 6.105 * np.exp(17.27 * Ta / (237.7 + Ta))\n",
    "    UTCI = Ta + 0.607562 + 0.022771 * Ta - 0.003578 * RH - 0.000119 * Ta * RH\n",
    "    return UTCI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec0c2d2-3e7a-4b7f-8394-a0857e623086",
   "metadata": {},
   "source": [
    "#### Verifica sul singolo timestamp del superamento o meno di tutte le soglie di pericolositÃ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54681242-8477-43be-8d8f-adfe4e91e321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Confronto Indici vs Soglie per il timestamp selezionato (2023-07-19T14:00:00.000000000) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_214f0_row0_col7, #T_214f0_row0_col8, #T_214f0_row0_col9, #T_214f0_row0_col10, #T_214f0_row0_col11, #T_214f0_row1_col9, #T_214f0_row1_col10, #T_214f0_row1_col11, #T_214f0_row2_col9, #T_214f0_row2_col10, #T_214f0_row2_col11, #T_214f0_row3_col9, #T_214f0_row3_col10, #T_214f0_row3_col11, #T_214f0_row4_col9, #T_214f0_row4_col10, #T_214f0_row4_col11 {\n",
       "  color: red;\n",
       "}\n",
       "#T_214f0_row1_col7, #T_214f0_row1_col8, #T_214f0_row2_col7, #T_214f0_row2_col8, #T_214f0_row3_col7, #T_214f0_row3_col8, #T_214f0_row4_col7, #T_214f0_row4_col8 {\n",
       "  color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_214f0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_214f0_level0_col0\" class=\"col_heading level0 col0\" >Indice</th>\n",
       "      <th id=\"T_214f0_level0_col1\" class=\"col_heading level0 col1\" >Media (Â°C)</th>\n",
       "      <th id=\"T_214f0_level0_col2\" class=\"col_heading level0 col2\" >Mediana (Â°C)</th>\n",
       "      <th id=\"T_214f0_level0_col3\" class=\"col_heading level0 col3\" >95Â° Perc. (Â°C)</th>\n",
       "      <th id=\"T_214f0_level0_col4\" class=\"col_heading level0 col4\" >99Â° Perc. (Â°C)</th>\n",
       "      <th id=\"T_214f0_level0_col5\" class=\"col_heading level0 col5\" >Massimo (Â°C)</th>\n",
       "      <th id=\"T_214f0_level0_col6\" class=\"col_heading level0 col6\" >Soglia (Â°C)</th>\n",
       "      <th id=\"T_214f0_level0_col7\" class=\"col_heading level0 col7\" >Media > Soglia</th>\n",
       "      <th id=\"T_214f0_level0_col8\" class=\"col_heading level0 col8\" >Mediana > Soglia</th>\n",
       "      <th id=\"T_214f0_level0_col9\" class=\"col_heading level0 col9\" >95Â° Perc. > Soglia</th>\n",
       "      <th id=\"T_214f0_level0_col10\" class=\"col_heading level0 col10\" >99Â° Perc. > Soglia</th>\n",
       "      <th id=\"T_214f0_level0_col11\" class=\"col_heading level0 col11\" >Massimo > Soglia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_214f0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_214f0_row0_col0\" class=\"data row0 col0\" >Heat Index</td>\n",
       "      <td id=\"T_214f0_row0_col1\" class=\"data row0 col1\" >118.314140</td>\n",
       "      <td id=\"T_214f0_row0_col2\" class=\"data row0 col2\" >96.854263</td>\n",
       "      <td id=\"T_214f0_row0_col3\" class=\"data row0 col3\" >240.163476</td>\n",
       "      <td id=\"T_214f0_row0_col4\" class=\"data row0 col4\" >279.980493</td>\n",
       "      <td id=\"T_214f0_row0_col5\" class=\"data row0 col5\" >342.129150</td>\n",
       "      <td id=\"T_214f0_row0_col6\" class=\"data row0 col6\" >40.600000</td>\n",
       "      <td id=\"T_214f0_row0_col7\" class=\"data row0 col7\" >si</td>\n",
       "      <td id=\"T_214f0_row0_col8\" class=\"data row0 col8\" >si</td>\n",
       "      <td id=\"T_214f0_row0_col9\" class=\"data row0 col9\" >si</td>\n",
       "      <td id=\"T_214f0_row0_col10\" class=\"data row0 col10\" >si</td>\n",
       "      <td id=\"T_214f0_row0_col11\" class=\"data row0 col11\" >si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_214f0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_214f0_row1_col0\" class=\"data row1 col0\" >Humidex</td>\n",
       "      <td id=\"T_214f0_row1_col1\" class=\"data row1 col1\" >35.685900</td>\n",
       "      <td id=\"T_214f0_row1_col2\" class=\"data row1 col2\" >39.193636</td>\n",
       "      <td id=\"T_214f0_row1_col3\" class=\"data row1 col3\" >46.237870</td>\n",
       "      <td id=\"T_214f0_row1_col4\" class=\"data row1 col4\" >47.055923</td>\n",
       "      <td id=\"T_214f0_row1_col5\" class=\"data row1 col5\" >47.998297</td>\n",
       "      <td id=\"T_214f0_row1_col6\" class=\"data row1 col6\" >45.000000</td>\n",
       "      <td id=\"T_214f0_row1_col7\" class=\"data row1 col7\" >no</td>\n",
       "      <td id=\"T_214f0_row1_col8\" class=\"data row1 col8\" >no</td>\n",
       "      <td id=\"T_214f0_row1_col9\" class=\"data row1 col9\" >si</td>\n",
       "      <td id=\"T_214f0_row1_col10\" class=\"data row1 col10\" >si</td>\n",
       "      <td id=\"T_214f0_row1_col11\" class=\"data row1 col11\" >si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_214f0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_214f0_row2_col0\" class=\"data row2 col0\" >Lethal Heat Stress Index</td>\n",
       "      <td id=\"T_214f0_row2_col1\" class=\"data row2 col1\" >23.711643</td>\n",
       "      <td id=\"T_214f0_row2_col2\" class=\"data row2 col2\" >25.642181</td>\n",
       "      <td id=\"T_214f0_row2_col3\" class=\"data row2 col3\" >28.233986</td>\n",
       "      <td id=\"T_214f0_row2_col4\" class=\"data row2 col4\" >28.735695</td>\n",
       "      <td id=\"T_214f0_row2_col5\" class=\"data row2 col5\" >29.360319</td>\n",
       "      <td id=\"T_214f0_row2_col6\" class=\"data row2 col6\" >27.000000</td>\n",
       "      <td id=\"T_214f0_row2_col7\" class=\"data row2 col7\" >no</td>\n",
       "      <td id=\"T_214f0_row2_col8\" class=\"data row2 col8\" >no</td>\n",
       "      <td id=\"T_214f0_row2_col9\" class=\"data row2 col9\" >si</td>\n",
       "      <td id=\"T_214f0_row2_col10\" class=\"data row2 col10\" >si</td>\n",
       "      <td id=\"T_214f0_row2_col11\" class=\"data row2 col11\" >si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_214f0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_214f0_row3_col0\" class=\"data row3 col0\" >UTCI</td>\n",
       "      <td id=\"T_214f0_row3_col1\" class=\"data row3 col1\" >34.902576</td>\n",
       "      <td id=\"T_214f0_row3_col2\" class=\"data row3 col2\" >37.245007</td>\n",
       "      <td id=\"T_214f0_row3_col3\" class=\"data row3 col3\" >45.357663</td>\n",
       "      <td id=\"T_214f0_row3_col4\" class=\"data row3 col4\" >46.129793</td>\n",
       "      <td id=\"T_214f0_row3_col5\" class=\"data row3 col5\" >47.215469</td>\n",
       "      <td id=\"T_214f0_row3_col6\" class=\"data row3 col6\" >44.000000</td>\n",
       "      <td id=\"T_214f0_row3_col7\" class=\"data row3 col7\" >no</td>\n",
       "      <td id=\"T_214f0_row3_col8\" class=\"data row3 col8\" >no</td>\n",
       "      <td id=\"T_214f0_row3_col9\" class=\"data row3 col9\" >si</td>\n",
       "      <td id=\"T_214f0_row3_col10\" class=\"data row3 col10\" >si</td>\n",
       "      <td id=\"T_214f0_row3_col11\" class=\"data row3 col11\" >si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_214f0_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_214f0_row4_col0\" class=\"data row4 col0\" >WBGT</td>\n",
       "      <td id=\"T_214f0_row4_col1\" class=\"data row4 col1\" >23.903841</td>\n",
       "      <td id=\"T_214f0_row4_col2\" class=\"data row4 col2\" >26.076931</td>\n",
       "      <td id=\"T_214f0_row4_col3\" class=\"data row4 col3\" >29.661166</td>\n",
       "      <td id=\"T_214f0_row4_col4\" class=\"data row4 col4\" >30.078764</td>\n",
       "      <td id=\"T_214f0_row4_col5\" class=\"data row4 col5\" >30.556419</td>\n",
       "      <td id=\"T_214f0_row4_col6\" class=\"data row4 col6\" >28.000000</td>\n",
       "      <td id=\"T_214f0_row4_col7\" class=\"data row4 col7\" >no</td>\n",
       "      <td id=\"T_214f0_row4_col8\" class=\"data row4 col8\" >no</td>\n",
       "      <td id=\"T_214f0_row4_col9\" class=\"data row4 col9\" >si</td>\n",
       "      <td id=\"T_214f0_row4_col10\" class=\"data row4 col10\" >si</td>\n",
       "      <td id=\"T_214f0_row4_col11\" class=\"data row4 col11\" >si</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x224fb540700>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# **Seleziona un timestamp specifico**\n",
    "time_selected = dataset3['T_2M'].time[23475]\n",
    "\n",
    "# **Estrai temperatura e dew point temperature per il primo timestamp**\n",
    "temperature_snapshot = dataset3['T_2M'].sel(time=time_selected)\n",
    "dew_point_snapshot = dataset2['TD_2M'].sel(time=time_selected)\n",
    "\n",
    "# **Filtra valori anomali e interpoliamo dew point temperature**\n",
    "dew_point_filtered = dew_point_snapshot.where(dew_point_snapshot > 243.15)\n",
    "dew_point_interpolated = dew_point_filtered.interpolate_na(dim='rlat', method='linear').interpolate_na(dim='rlon', method='linear')\n",
    "\n",
    "# **Calcola gli indici per ciascun pixel**\n",
    "humidex_snapshot = calculate_humidex(temperature_snapshot, dew_point_interpolated)\n",
    "relative_humidity_snapshot = calculate_relative_humidity(temperature_snapshot - 273.15, dew_point_interpolated - 273.15)\n",
    "heat_index_snapshot = calculate_heat_index(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "wbt_snapshot = calculate_wbt(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "wbgt_snapshot = calculate_wbgt(temperature_snapshot - 273.15, wbt_snapshot)\n",
    "lhs_snapshot = calculate_lethal_heat_stress_index(wbt_snapshot, relative_humidity_snapshot)\n",
    "utci_snapshot = calculate_utci(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "\n",
    "# **Calcola statistiche per ciascun indice**\n",
    "def calculate_stats(data_array):\n",
    "    return {\n",
    "        \"mean\": data_array.mean().item(),\n",
    "        \"median\": data_array.median().item(),\n",
    "        \"p95\": np.percentile(data_array, 95),\n",
    "        \"p99\": np.percentile(data_array, 99),\n",
    "        \"max\": data_array.max().item()\n",
    "    }\n",
    "\n",
    "indices = {\n",
    "    \"Heat Index\": heat_index_snapshot,\n",
    "    \"Humidex\": humidex_snapshot,\n",
    "    \"Lethal Heat Stress Index\": lhs_snapshot,\n",
    "    \"UTCI\": utci_snapshot,\n",
    "    \"WBGT\": wbgt_snapshot\n",
    "}\n",
    "\n",
    "stats_results = {key: calculate_stats(value) for key, value in indices.items()}\n",
    "\n",
    "# **Definizione delle soglie per ciascun indice**\n",
    "soglie = {\n",
    "    \"Heat Index\": 40.6,\n",
    "    \"Humidex\": 45,\n",
    "    \"Lethal Heat Stress Index\": 27,\n",
    "    \"UTCI\": 44,      # By literature is 46\n",
    "    \"WBGT\": 28       # By literature is 30\n",
    "}\n",
    "\n",
    "# **Creazione del DataFrame con i risultati**\n",
    "df_results = pd.DataFrame([\n",
    "    {\n",
    "        \"Indice\": key,\n",
    "        \"Media (Â°C)\": value[\"mean\"],\n",
    "        \"Mediana (Â°C)\": value[\"median\"],\n",
    "        \"95Â° Perc. (Â°C)\": value[\"p95\"],\n",
    "        \"99Â° Perc. (Â°C)\": value[\"p99\"],\n",
    "        \"Massimo (Â°C)\": value[\"max\"],\n",
    "        \"Soglia (Â°C)\": soglie[key],\n",
    "        \"Media > Soglia\": \"si\" if value[\"mean\"] > soglie[key] else \"no\",\n",
    "        \"Mediana > Soglia\": \"si\" if value[\"median\"] > soglie[key] else \"no\",\n",
    "        \"95Â° Perc. > Soglia\": \"si\" if value[\"p95\"] > soglie[key] else \"no\",\n",
    "        \"99Â° Perc. > Soglia\": \"si\" if value[\"p99\"] > soglie[key] else \"no\",\n",
    "        \"Massimo > Soglia\": \"si\" if value[\"max\"] > soglie[key] else \"no\"\n",
    "    }\n",
    "    for key, value in stats_results.items()\n",
    "])\n",
    "\n",
    "# **Ordina il DataFrame**\n",
    "df_results.sort_values(by=\"Indice\", inplace=True)\n",
    "\n",
    "# **Funzione per colorare i \"si\" di rosso e i \"no\" di verde**\n",
    "def color_superamento(val):\n",
    "    color = \"red\" if val == \"si\" else \"green\"\n",
    "    return f\"color: {color}\"\n",
    "\n",
    "# **Applica la formattazione condizionale**\n",
    "df_styled = df_results.style.applymap(color_superamento, subset=[\"Media > Soglia\", \"Mediana > Soglia\", \"95Â° Perc. > Soglia\", \"99Â° Perc. > Soglia\", \"Massimo > Soglia\"])\n",
    "\n",
    "# **Visualizza il DataFrame formattato con il timestamp in analisi**\n",
    "print(f\"\\n=== Confronto Indici vs Soglie per il timestamp selezionato ({str(time_selected.values)}) ===\")\n",
    "df_styled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39277130-47d8-4ad4-bc5c-f16f495e958f",
   "metadata": {},
   "source": [
    "#### Criterias to identify heat waves\n",
    "\n",
    "| Index | Threshold value by literature | Threshold value used |\n",
    "|:--|:--|:--|\n",
    "| Heat Index (HI) | > 105Â°F (~40.6Â°C) |\n",
    "| Humidex (Hu) | > 45Â°C |\n",
    "| WBGT | > 30Â°C | > 28Â°C |\n",
    "| Lethal Heat Stress Index (Ls) | > 27Â°C |\n",
    "| UTCI | > 46Â°C | > 44Â°C |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b33c0bf-8c47-4ed9-a93b-c4cbdc07e6a7",
   "metadata": {},
   "source": [
    "#### Verifica su tutti i timestamp di un anno del superamento o meno di tutte le soglie di pericolositÃ  & selezione dei giorni consecutivi in cui ciÃ² accade -> heat wave vs casi isolati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78333e34-678a-4686-93f9-426a2c20734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# **Seleziona un anno specifico per l'analisi**\n",
    "year = 2022\n",
    "timestamps = dataset3['T_2M'].time.sel(time=dataset3['T_2M'].time.dt.year == year)\n",
    "\n",
    "# **Definizione delle soglie per ciascun indice**\n",
    "soglie = {\n",
    "    \"Heat Index\": 40.6,\n",
    "    \"Humidex\": 45,\n",
    "    \"Lethal Heat Stress Index\": 27,\n",
    "    \"UTCI\": 46,\n",
    "    \"WBGT\": 30\n",
    "}\n",
    "\n",
    "# **Lista per salvare i risultati finali**\n",
    "heatwave_records = []\n",
    "\n",
    "# **Itera su tutti i timestamp dell'anno selezionato**\n",
    "for i, time_selected in enumerate(timestamps):\n",
    "    \n",
    "    # **Estrai temperatura e dew point per il timestamp attuale**\n",
    "    temperature_snapshot = dataset3['T_2M'].sel(time=time_selected)\n",
    "    dew_point_snapshot = dataset2['TD_2M'].sel(time=time_selected)\n",
    "    \n",
    "    # **Filtra valori anomali e interpoliamo dew point temperature**\n",
    "    dew_point_filtered = dew_point_snapshot.where(dew_point_snapshot > 243.15)\n",
    "    dew_point_interpolated = dew_point_filtered.interpolate_na(dim='rlat', method='linear').interpolate_na(dim='rlon', method='linear')\n",
    "\n",
    "    # **Calcola gli indici per ciascun pixel**\n",
    "    humidex_snapshot = calculate_humidex(temperature_snapshot, dew_point_interpolated)\n",
    "    relative_humidity_snapshot = calculate_relative_humidity(temperature_snapshot - 273.15, dew_point_interpolated - 273.15)\n",
    "    heat_index_snapshot = calculate_heat_index(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "    wbt_snapshot = calculate_wbt(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "    wbgt_snapshot = calculate_wbgt(temperature_snapshot - 273.15, wbt_snapshot)\n",
    "    lhs_snapshot = calculate_lethal_heat_stress_index(wbt_snapshot, relative_humidity_snapshot)\n",
    "    utci_snapshot = calculate_utci(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "\n",
    "    # **Calcola statistiche per ciascun indice**\n",
    "    def calculate_stats(data_array):\n",
    "        return {\n",
    "            \"mean\": data_array.mean().item(),\n",
    "            \"median\": data_array.median().item(),\n",
    "            \"p95\": np.percentile(data_array, 95),\n",
    "            \"p99\": np.percentile(data_array, 99),\n",
    "            \"max\": data_array.max().item()\n",
    "        }\n",
    "\n",
    "    indices = {\n",
    "        \"Heat Index\": heat_index_snapshot,\n",
    "        \"Humidex\": humidex_snapshot,\n",
    "        \"Lethal Heat Stress Index\": lhs_snapshot,\n",
    "        \"UTCI\": utci_snapshot,\n",
    "        \"WBGT\": wbgt_snapshot\n",
    "    }\n",
    "\n",
    "    stats_results = {key: calculate_stats(value) for key, value in indices.items()}\n",
    "\n",
    "    # **Verifica se TUTTI gli indici superano almeno in una delle colonne le soglie**\n",
    "    all_exceed = all(\n",
    "        any([\n",
    "            stats_results[key][\"mean\"] > soglie[key],\n",
    "            stats_results[key][\"median\"] > soglie[key],\n",
    "            stats_results[key][\"p95\"] > soglie[key],\n",
    "            stats_results[key][\"p99\"] > soglie[key],\n",
    "            stats_results[key][\"max\"] > soglie[key]\n",
    "        ])\n",
    "        for key in indices.keys()\n",
    "    )\n",
    "\n",
    "    # **Se la condizione Ã¨ soddisfatta, salva il risultato**\n",
    "    if all_exceed:\n",
    "        \n",
    "        df_results = pd.DataFrame([\n",
    "            {\n",
    "                \"Indice\": key,\n",
    "                \"Media (Â°C)\": value[\"mean\"],\n",
    "                \"Mediana (Â°C)\": value[\"median\"],\n",
    "                \"95Â° Perc. (Â°C)\": value[\"p95\"],\n",
    "                \"99Â° Perc. (Â°C)\": value[\"p99\"],\n",
    "                \"Massimo (Â°C)\": value[\"max\"],\n",
    "                \"Soglia (Â°C)\": soglie[key],\n",
    "                \"Media > Soglia\": \"si\" if value[\"mean\"] > soglie[key] else \"no\",\n",
    "                \"Mediana > Soglia\": \"si\" if value[\"median\"] > soglie[key] else \"no\",\n",
    "                \"95Â° Perc. > Soglia\": \"si\" if value[\"p95\"] > soglie[key] else \"no\",\n",
    "                \"99Â° Perc. > Soglia\": \"si\" if value[\"p99\"] > soglie[key] else \"no\",\n",
    "                \"Massimo > Soglia\": \"si\" if value[\"max\"] > soglie[key] else \"no\"\n",
    "            }\n",
    "            for key, value in stats_results.items()\n",
    "        ])\n",
    "        \n",
    "        # **Aggiunta di timestamp nel dataframe per chiarezza**\n",
    "        df_results.insert(0, \"Timestamp\", str(time_selected.values))\n",
    "        df_results.insert(1, \"Numero Timestamp\", i)\n",
    "\n",
    "        # **Aggiungi i risultati alla lista per il salvataggio**\n",
    "        heatwave_records.extend(df_results.to_dict(orient=\"records\"))\n",
    "\n",
    "# **Creazione del DataFrame finale**\n",
    "df_heatwave = pd.DataFrame(heatwave_records)\n",
    "\n",
    "# **Identificazione di heat wave e casi isolati**\n",
    "df_heatwave[\"Data\"] = pd.to_datetime(df_heatwave[\"Timestamp\"]).dt.date\n",
    "df_heatwave[\"Heat Wave\"] = \"caso isolato\"\n",
    "\n",
    "for i, row in df_heatwave.iterrows():\n",
    "    current_date = row[\"Data\"]\n",
    "    next_day = current_date + pd.Timedelta(days=1)\n",
    "    prev_day = current_date - pd.Timedelta(days=1)\n",
    "\n",
    "    if ((next_day in df_heatwave[\"Data\"].values) or (prev_day in df_heatwave[\"Data\"].values)):\n",
    "        df_heatwave.at[i, \"Heat Wave\"] = \"heat wave\"\n",
    "\n",
    "# **Salvataggio su file CSV con nome contenente l'anno**\n",
    "df_heatwave.to_csv(f\"heatwave_timestamps_{year}.csv\", index=False)\n",
    "\n",
    "# **Controllo per stampare il messaggio appropriato**\n",
    "print(\"\\n=== Giorni con Ondate di Calore Estreme dell'anno selezionato ===\")\n",
    "if df_heatwave.empty:\n",
    "    print(\"Nessun giorno dell'anno selezionato ha superato tutte le soglie di pericolositÃ  per il caldo estremo nel 95Â° percentile.\")\n",
    "else:\n",
    "    print(\"Stampa nella cella successiva df_heatwave per vederlo in formato data frame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade8a5d-f8b1-4da2-9613-e48bb05392a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heatwave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b303b0-489c-430f-8a28-d2564228225c",
   "metadata": {},
   "source": [
    "#### GIF rappresentante il periodo prima durante e dopo la heat wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b1e93a16-1896-4722-a667-993f465d949e",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " GIF creata con successo: heatwave_evolution_2022.gif\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v2 as imageio  # Evita il warning di ImageIO\n",
    "import os\n",
    "\n",
    "# **Parametri personalizzabili**\n",
    "year = 2022  # Anno di analisi\n",
    "target_timestamp_index = 309  # Numero del timestamp di riferimento (cambiabile dall'utente)\n",
    "days_before = 10  # Giorni precedenti da mostrare\n",
    "days_after = 12  # Giorni successivi da mostrare\n",
    "indice_selezionato = \"Heat Index\"  # Indice da visualizzare nella mappa\n",
    "\n",
    "# **Caricamento dei dati**\n",
    "timestamps = dataset3['T_2M'].time.sel(time=dataset3['T_2M'].time.dt.year == year)\n",
    "df_heatwave[\"Data\"] = pd.to_datetime(df_heatwave[\"Timestamp\"]).dt.date\n",
    "heatwave_days = df_heatwave[df_heatwave['Heat Wave'] == 'heat wave']['Data'].unique()\n",
    "heatwave_dates = set(str(date) for date in heatwave_days)  # Set di date formattate\n",
    "\n",
    "# **Seleziona il timestamp di riferimento**\n",
    "target_time = timestamps[target_timestamp_index]\n",
    "\n",
    "# **Definiamo l'intervallo temporale per la GIF**\n",
    "start_time = target_time - np.timedelta64(days_before, 'D')\n",
    "end_time = target_time + np.timedelta64(days_after, 'D')\n",
    "time_range = timestamps.sel(time=(timestamps >= start_time) & (timestamps <= end_time))\n",
    "\n",
    "# **Calcola il range fisso per la legenda solo sui timestamp selezionati**\n",
    "heat_index_values = []\n",
    "for time_selected in time_range:\n",
    "    temperature_snapshot = dataset3['T_2M'].sel(time=time_selected)\n",
    "    dew_point_snapshot = dataset2['TD_2M'].sel(time=time_selected)\n",
    "    dew_point_filtered = dew_point_snapshot.where(dew_point_snapshot > 243.15)\n",
    "    dew_point_interpolated = dew_point_filtered.interpolate_na(dim='rlat', method='linear').interpolate_na(dim='rlon', method='linear')\n",
    "    heat_index_snapshot = calculate_heat_index(temperature_snapshot - 273.15, calculate_relative_humidity(temperature_snapshot - 273.15, dew_point_interpolated - 273.15))\n",
    "    heat_index_values.append(heat_index_snapshot.values)\n",
    "\n",
    "heat_index_values = np.concatenate([hi.flatten() for hi in heat_index_values])\n",
    "heat_index_min = heat_index_values.min()\n",
    "heat_index_max = heat_index_values.max()\n",
    "\n",
    "# **Creazione di una cartella temporanea per le immagini**\n",
    "output_folder = \"temp_frames\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# **Genera i frame per la GIF**\n",
    "frames = []\n",
    "for time_selected in time_range:\n",
    "    \n",
    "    # **Estrai i dati di temperatura e dew point**\n",
    "    temperature_snapshot = dataset3['T_2M'].sel(time=time_selected)\n",
    "    dew_point_snapshot = dataset2['TD_2M'].sel(time=time_selected)\n",
    "    \n",
    "    # **Filtra valori anomali e interpoliamo dew point temperature**\n",
    "    dew_point_filtered = dew_point_snapshot.where(dew_point_snapshot > 243.15)\n",
    "    dew_point_interpolated = dew_point_filtered.interpolate_na(dim='rlat', method='linear').interpolate_na(dim='rlon', method='linear')\n",
    "    \n",
    "    # **Calcola gli indici**\n",
    "    heat_index_snapshot = calculate_heat_index(temperature_snapshot - 273.15, calculate_relative_humidity(temperature_snapshot - 273.15, dew_point_interpolated - 273.15))\n",
    "    \n",
    "    # **Plotta la distribuzione dell'Heat Index per il timestamp corrente**\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    im = ax.imshow(heat_index_snapshot, cmap=\"inferno\", origin=\"lower\", vmin=heat_index_min, vmax=heat_index_max)\n",
    "    \n",
    "    # **Legenda fissa**\n",
    "    cbar = plt.colorbar(im, label=\"Heat Index (Â°C)\")\n",
    "    cbar.ax.tick_params(labelsize=10)\n",
    "    \n",
    "    # **Aggiungi il titolo con il timestamp e indicazione della heatwave**\n",
    "    timestamp_str = str(time_selected.values)[:16]\n",
    "    ax.set_title(timestamp_str, fontsize=14, fontweight=\"bold\", ha='left', x=0)\n",
    "    \n",
    "    # **Se il giorno Ã¨ una heatwave, evidenzia il riquadro e mostra la scritta**\n",
    "    date_str = timestamp_str[:10]  # Estrai solo la parte di data\n",
    "    if date_str in heatwave_dates:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('red')\n",
    "            spine.set_linewidth(3)\n",
    "        ax.text(0.5, -0.1, \"HEAT WAVE HIT\", fontsize=18, color='red', ha='center', transform=ax.transAxes, fontweight='bold')\n",
    "    \n",
    "    # **Sostituisci i caratteri speciali per evitare errori nei nomi dei file**\n",
    "    safe_timestamp = timestamp_str.replace(\":\", \"-\").replace(\"T\", \"_\").split(\".\")[0]\n",
    "    frame_filename = os.path.join(output_folder, f\"frame_{safe_timestamp}.png\")\n",
    "\n",
    "    # **Salva il frame temporaneo**\n",
    "    plt.savefig(frame_filename, dpi=100)\n",
    "    plt.close()\n",
    "    \n",
    "    frames.append(frame_filename)\n",
    "\n",
    "# **Creazione della GIF**\n",
    "gif_filename = f\"heatwave_evolution_{year}.gif\"\n",
    "with imageio.get_writer(gif_filename, mode='I', duration=5) as writer:\n",
    "    for frame in frames:\n",
    "        image = imageio.imread(frame)\n",
    "        writer.append_data(image)\n",
    "\n",
    "# **Pulizia della cartella temporanea**\n",
    "for frame in frames:\n",
    "    try:\n",
    "        os.remove(frame)\n",
    "    except PermissionError:\n",
    "        pass  # Ignora errori se il file Ã¨ ancora in uso\n",
    "try:\n",
    "    os.rmdir(output_folder)\n",
    "except PermissionError:\n",
    "    pass  # Ignora errori se la cartella Ã¨ ancora in uso\n",
    "\n",
    "print(f\"\\n GIF creata con successo: {gif_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617eb930-c42a-427e-b1b3-c267c11ee7bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Iterazione dall'inizio del dataset del superamento o meno di tutte le soglie di pericolositÃ  per tutti gli anni, che si arresta quando trovato un anno con almeno un timestamp che supera tutte le soglie di pericolositÃ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c81b1ce-1730-409d-a8f6-de27305920f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Analizzando l'anno 1981...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1982...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1983...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1984...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1985...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1986...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1987...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1988...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1989...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1990...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1991...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1992...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1993...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1994...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1995...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1996...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1997...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1998...\n",
      "\n",
      "ðŸ” Analizzando l'anno 1999...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2000...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2001...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2002...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2003...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2004...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2005...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2006...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2007...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2008...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2009...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2010...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2011...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2012...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2013...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2014...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2015...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2016...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2017...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2018...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2019...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2020...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2021...\n",
      "\n",
      "ðŸ” Analizzando l'anno 2022...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m humidex_snapshot \u001b[38;5;241m=\u001b[39m calculate_humidex(temperature_snapshot, dew_point_interpolated)\n\u001b[0;32m     42\u001b[0m relative_humidity_snapshot \u001b[38;5;241m=\u001b[39m calculate_relative_humidity(temperature_snapshot \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m273.15\u001b[39m, dew_point_interpolated \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m273.15\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m heat_index_snapshot \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_heat_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemperature_snapshot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m273.15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelative_humidity_snapshot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m wbt_snapshot \u001b[38;5;241m=\u001b[39m calculate_wbt(temperature_snapshot \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m273.15\u001b[39m, relative_humidity_snapshot)\n\u001b[0;32m     45\u001b[0m wbgt_snapshot \u001b[38;5;241m=\u001b[39m calculate_wbgt(temperature_snapshot \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m273.15\u001b[39m, wbt_snapshot)\n",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m, in \u001b[0;36mcalculate_heat_index\u001b[1;34m(Ta, RH)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcalculate_heat_index\u001b[39m(Ta, RH):\n\u001b[1;32m----> 6\u001b[0m     HI \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m42.379\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.04901523\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10.14333127\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRH\u001b[49m\n\u001b[0;32m      7\u001b[0m           \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.22475541\u001b[39m \u001b[38;5;241m*\u001b[39m Ta \u001b[38;5;241m*\u001b[39m RH \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m6.8378e-3\u001b[39m \u001b[38;5;241m*\u001b[39m Ta\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      8\u001b[0m           \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m5.48172e-2\u001b[39m \u001b[38;5;241m*\u001b[39m RH\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.229e-3\u001b[39m \u001b[38;5;241m*\u001b[39m Ta\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m RH\n\u001b[0;32m      9\u001b[0m           \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m8.528e-4\u001b[39m \u001b[38;5;241m*\u001b[39m Ta \u001b[38;5;241m*\u001b[39m RH\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.99e-6\u001b[39m \u001b[38;5;241m*\u001b[39m Ta\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m RH\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m HI\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\_typed_ops.py:206\u001b[0m, in \u001b[0;36mDataArrayOpsMixin.__add__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_binary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\dataarray.py:4371\u001b[0m, in \u001b[0;36mDataArray._binary_op\u001b[1;34m(self, other, f, reflexive)\u001b[0m\n\u001b[0;32m   4364\u001b[0m other_coords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(other, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoords\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   4366\u001b[0m variable \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4367\u001b[0m     f(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariable, other_variable)\n\u001b[0;32m   4368\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reflexive\n\u001b[0;32m   4369\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m f(other_variable, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariable)\n\u001b[0;32m   4370\u001b[0m )\n\u001b[1;32m-> 4371\u001b[0m coords, indexes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreflexive\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4372\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_name(other)\n\u001b[0;32m   4374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replace(variable, coords, name, indexes\u001b[38;5;241m=\u001b[39mindexes)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\coordinates.py:186\u001b[0m, in \u001b[0;36mCoordinates._merge_raw\u001b[1;34m(self, other, reflexive)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     coord_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m, other] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reflexive \u001b[38;5;28;01melse\u001b[39;00m [other, \u001b[38;5;28mself\u001b[39m]\n\u001b[1;32m--> 186\u001b[0m     variables, indexes \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_coordinates_without_align\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoord_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m variables, indexes\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\merge.py:420\u001b[0m, in \u001b[0;36mmerge_coordinates_without_align\u001b[1;34m(objects, prioritized, exclude_dims, combine_attrs)\u001b[0m\n\u001b[0;32m    416\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m collected\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# TODO: indexes should probably be filtered in collected elements\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# before merging them\u001b[39;00m\n\u001b[1;32m--> 420\u001b[0m merged_coords, merged_indexes \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprioritized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    423\u001b[0m merged_indexes \u001b[38;5;241m=\u001b[39m filter_indexes_from_coords(merged_indexes, \u001b[38;5;28mset\u001b[39m(merged_coords))\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merged_coords, merged_indexes\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\merge.py:302\u001b[0m, in \u001b[0;36mmerge_collected\u001b[1;34m(grouped, prioritized, compat, combine_attrs, equals)\u001b[0m\n\u001b[0;32m    300\u001b[0m variables \u001b[38;5;241m=\u001b[39m [variable \u001b[38;5;28;01mfor\u001b[39;00m variable, _ \u001b[38;5;129;01min\u001b[39;00m elements_list]\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 302\u001b[0m     merged_vars[name] \u001b[38;5;241m=\u001b[39m \u001b[43munique_variable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mequals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MergeError:\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compat \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;66;03m# we need more than \"minimal\" compatibility (for which\u001b[39;00m\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;66;03m# we drop conflicting coordinates)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\merge.py:149\u001b[0m, in \u001b[0;36munique_variable\u001b[1;34m(name, variables, compat, equals)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m equals \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;66;03m# now compare values with minimum number of computes\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m variables[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m    151\u001b[0m         equals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(out, compat)(var)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\variable.py:563\u001b[0m, in \u001b[0;36mVariable.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this variable's data from disk or a\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03mremote source into memory and return a new variable. The original is\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;124;03mleft unaltered.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;124;03mdask.array.compute\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    562\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\variable.py:538\u001b[0m, in \u001b[0;36mVariable.load\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    522\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this variable's data from disk or a\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;124;03m    remote source into memory and return this variable.\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03m    dask.array.compute\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_duck_dask_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    539\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m as_compatible_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcompute(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_duck_array(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\pycompat.py:81\u001b[0m, in \u001b[0;36mis_duck_dask_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mis_duck_dask_array\u001b[39m(x):\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m is_duck_array(x) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mis_dask_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\pycompat.py:73\u001b[0m, in \u001b[0;36mis_dask_collection\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mis_dask_collection\u001b[39m(x):\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmodule_available\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_dask_collection\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m is_dask_collection(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\site-packages\\xarray\\core\\utils.py:1161\u001b[0m, in \u001b[0;36mmodule_available\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmodule_available\u001b[39m(module: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Checks whether a module is installed without importing it.\u001b[39;00m\n\u001b[0;32m   1148\u001b[0m \n\u001b[0;32m   1149\u001b[0m \u001b[38;5;124;03m    Use this for a lightweight check and lazy imports.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;124;03m        Whether the module is installed.\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geoinfprj\\lib\\importlib\\util.py:103\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    102\u001b[0m         parent_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_find_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[fullname]\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:914\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1407\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1379\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1506\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:142\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# **Definizione delle soglie per ciascun indice**\n",
    "soglie = {\n",
    "    \"Heat Index\": 40.6,\n",
    "    \"Humidex\": 45,\n",
    "    \"Lethal Heat Stress Index\": 27,\n",
    "    \"UTCI\": 46,\n",
    "    \"WBGT\": 30\n",
    "}\n",
    "\n",
    "# **Ottieni tutti gli anni disponibili nel dataset**\n",
    "anni_disponibili = np.unique(dataset3['T_2M'].time.dt.year.values)\n",
    "\n",
    "# **Variabile per verificare se abbiamo trovato un anno con heatwave**\n",
    "anno_trovato = False\n",
    "\n",
    "# **Iteriamo su tutti gli anni disponibili**\n",
    "for year in anni_disponibili:\n",
    "    if anno_trovato:\n",
    "        break  # Se abbiamo giÃ  trovato un anno valido, interrompiamo il loop\n",
    "\n",
    "    print(f\"\\nðŸ” Analizzando l'anno {year}...\")\n",
    "\n",
    "    # **Seleziona i timestamp per l'anno corrente**\n",
    "    timestamps = dataset3['T_2M'].time.sel(time=dataset3['T_2M'].time.dt.year == year)\n",
    "\n",
    "    # **Lista per salvare i giorni in cui tutte le soglie vengono superate**\n",
    "    heatwave_days = []\n",
    "\n",
    "    # **Itera su tutti i timestamp dell'anno selezionato**\n",
    "    for time_selected in timestamps:\n",
    "        \n",
    "        # **Estrai temperatura e dew point per il timestamp attuale**\n",
    "        temperature_snapshot = dataset3['T_2M'].sel(time=time_selected)\n",
    "        dew_point_snapshot = dataset2['TD_2M'].sel(time=time_selected)\n",
    "        \n",
    "        # **Filtra valori anomali e interpoliamo dew point temperature**\n",
    "        dew_point_filtered = dew_point_snapshot.where(dew_point_snapshot > 243.15)\n",
    "        dew_point_interpolated = dew_point_filtered.interpolate_na(dim='rlat', method='linear').interpolate_na(dim='rlon', method='linear')\n",
    "\n",
    "        # **Calcola gli indici per ciascun pixel**\n",
    "        humidex_snapshot = calculate_humidex(temperature_snapshot, dew_point_interpolated)\n",
    "        relative_humidity_snapshot = calculate_relative_humidity(temperature_snapshot - 273.15, dew_point_interpolated - 273.15)\n",
    "        heat_index_snapshot = calculate_heat_index(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "        wbt_snapshot = calculate_wbt(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "        wbgt_snapshot = calculate_wbgt(temperature_snapshot - 273.15, wbt_snapshot)\n",
    "        lhs_snapshot = calculate_lethal_heat_stress_index(wbt_snapshot, relative_humidity_snapshot)\n",
    "        utci_snapshot = calculate_utci(temperature_snapshot - 273.15, relative_humidity_snapshot)\n",
    "\n",
    "        # **Calcola media e mediana per ciascun indice**\n",
    "        humidex_mean, humidex_median = humidex_snapshot.mean().item(), humidex_snapshot.median().item()\n",
    "        heat_index_mean, heat_index_median = heat_index_snapshot.mean().item(), heat_index_snapshot.median().item()\n",
    "        wbgt_mean, wbgt_median = wbgt_snapshot.mean().item(), wbgt_snapshot.median().item()\n",
    "        lhs_mean, lhs_median = lhs_snapshot.mean().item(), lhs_snapshot.median().item()\n",
    "        utci_mean, utci_median = utci_snapshot.mean().item(), utci_snapshot.median().item()\n",
    "\n",
    "        # **Verifica se tutti gli indici superano le soglie contemporaneamente**\n",
    "        all_indices_above_threshold = (\n",
    "            (heat_index_mean > soglie[\"Heat Index\"]) and (heat_index_median > soglie[\"Heat Index\"]) and\n",
    "            (humidex_mean > soglie[\"Humidex\"]) and (humidex_median > soglie[\"Humidex\"]) and\n",
    "            (lhs_mean > soglie[\"Lethal Heat Stress Index\"]) and (lhs_median > soglie[\"Lethal Heat Stress Index\"]) and\n",
    "            (utci_mean > soglie[\"UTCI\"]) and (utci_median > soglie[\"UTCI\"]) and\n",
    "            (wbgt_mean > soglie[\"WBGT\"]) and (wbgt_median > soglie[\"WBGT\"])\n",
    "        )\n",
    "\n",
    "        # **Se la condizione Ã¨ soddisfatta, aggiungiamo il giorno alla lista**\n",
    "        if all_indices_above_threshold:\n",
    "            heatwave_days.append(str(time_selected.values))\n",
    "            anno_trovato = True  # Imposta il flag per fermare la ricerca dopo questo anno\n",
    "\n",
    "    # **Se abbiamo trovato almeno un giorno, interrompiamo il loop**\n",
    "    if anno_trovato:\n",
    "        break\n",
    "\n",
    "# **Se abbiamo trovato un anno valido, creiamo il DataFrame**\n",
    "if anno_trovato and heatwave_days:\n",
    "    df_heatwave_days = pd.DataFrame({\"Heatwave Days\": heatwave_days})\n",
    "\n",
    "    # **Ordina i risultati in base alla data**\n",
    "    df_heatwave_days.sort_values(by=\"Heatwave Days\", inplace=True)\n",
    "\n",
    "    # **Esporta il DataFrame in un file CSV per visualizzazione**\n",
    "    df_heatwave_days.to_csv(f\"heatwave_days_{year}.csv\", index=False)\n",
    "\n",
    "    # **Stampa i risultati**\n",
    "    print(f\"\\n=== Giorni con Ondate di Calore Estreme nell'anno {year} ===\")\n",
    "    print(df_heatwave_days.to_string(index=False))\n",
    "\n",
    "else:\n",
    "    print(\"\\n Nessun anno nel dataset ha superato tutte le soglie di pericolositÃ  per il caldo estremo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af1a2b-c97c-4843-ae17-e66be072be53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
